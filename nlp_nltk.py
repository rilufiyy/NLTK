# -*- coding: utf-8 -*-
"""NLP-NLTK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LuBYYqTLKlTlnyxzDxvhRFLseVhBoIQ8
"""

pip install nltk

import nltk
nltk.download('popular')

import os
import nltk
import nltk.corpus

nltk.download('all')

print(os.listdir(nltk.data.find("corpora")))

import nltk
nltk.download('brown')

from nltk.corpus import brown
brown.words()

nltk.corpus.gutenberg.fileids()

hamlet=nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')
hamlet

for word in hamlet[:500]:
    print(word, sep=' ', end=' ')

AI = """In the Department of Computational Sciences at Westbridge University, a multidisciplinary research team was conducting a long-term study on adaptive learning algorithms. The project, funded by the National Research Foundation, aimed to understand how machine learning models behave when exposed to continuously shifting data distributions—an issue commonly known as concept drift. Rather than relying solely on standard benchmarks, the team created a complex simulation environment capable of generating dynamic, unpredictable patterns that closely resembled real-world scenarios.

Dr. Helena Morris, the principal investigator, emphasized that traditional evaluation methods were insufficient. According to her, many models performed exceptionally well in controlled settings but deteriorated rapidly when deployed in natural environments. To address this gap, the team adopted a hybrid methodological framework combining statistical analysis, reinforcement learning techniques, and information theory. Each week, they ran hundreds of experimental cycles, collecting terabytes of behavioral logs that required extensive preprocessing before they could be analyzed.

One of the major challenges the researchers encountered involved interpretability. Several machine learning algorithms demonstrated high accuracy, yet their decision-making processes remained opaque. To tackle this issue, a subgroup led by postdoctoral researcher Aaron Blake explored the use of explainable AI (XAI) techniques such as SHAP values, local surrogate models, and causal inference methods. Their goal was not only to understand how models reached certain outputs but also to identify potential biases embedded within the training data.

While the technical work progressed, another team focused on ensuring the reproducibility of the findings. They built a comprehensive documentation pipeline that tracked every experimental parameter, from hyperparameter configurations to software versions used during training. This level of transparency, though time-consuming, was essential for meeting the standards of journals such as Nature Machine Intelligence and IEEE Transactions on Neural Networks and Learning Systems.

Despite the careful planning, unexpected issues frequently arose. Some of the synthetic datasets produced anomalies that caused algorithmic behavior to diverge significantly from theoretical expectations. Instead of treating these anomalies as errors, the team investigated them further, believing that they might reveal underlying dynamics not captured by existing models. After several weeks of analysis, they discovered that certain patterns emerged only under specific noise conditions, suggesting a potential link between environmental stability and model robustness.

Near the end of the study’s third year, the team prepared to publish their preliminary results. The manuscript highlighted several key contributions: a new benchmark suite for evaluating adaptive learning algorithms, a detailed taxonomy of concept drift types, and a set of interpretability tools designed to monitor model behavior in real time. Peer reviewers were particularly impressed by the careful statistical validation and the breadth of interdisciplinary techniques used in the project.

As the research entered its final phase, Dr. Morris reflected on the broader implications of their findings. She believed that understanding how algorithms adapt—or fail to adapt—could fundamentally reshape the future of artificial intelligence. Whether in climate modeling, healthcare diagnostics, or autonomous systems, the ability to detect and respond to changing conditions was essential. The team’s work, she hoped, would serve as a foundation for future researchers to build upon, pushing the boundaries of what adaptive systems could achieve."""

type(AI)

from nltk.tokenize import word_tokenize

AI_tokens = word_tokenize(AI)
AI_tokens

len(AI_tokens)

from nltk.probability import FreqDist
fdist = FreqDist()

for word in AI_tokens:
  fdist[word.lower()]+=1
fdist

fdist['research']

len(fdist)

fdist_top10 = fdist.most_common(10)
fdist_top10

from nltk.tokenize import blankline_tokenize
AI_blank=blankline_tokenize(AI)
len(AI_blank)

AI_blank[2]

from nltk.util import bigrams, trigrams, ngrams

string = "The best and most beautiful things in the world cannot be seen or even touched, they must be felt with the heart"
quotes_tokens = nltk.word_tokenize(string)
quotes_tokens

quotes_bigrams = list(nltk.bigrams(quotes_tokens))
quotes_bigrams

quotes_trigrams = list(nltk.trigrams(quotes_tokens))
quotes_trigrams

quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))
quotes_ngrams

from nltk.stem import PorterStemmer
pst=PorterStemmer()

pst.stem("giving")

words_to_stem=["give", "giving", "given", "gave"]
for words in words_to_stem:
  print(words+ ":" +pst.stem(words))

from nltk.stem import LancasterStemmer

lst = LancasterStemmer()

for w in words_to_stem:
    print(w + ":" +lst.stem(w))

from nltk.stem import SnowballStemmer
sbst=SnowballStemmer('english')

for words in words_to_stem:
  print(words+ ":" +sbst.stem(words))

from nltk.stem import wordnet
from nltk.stem import WordNetLemmatizer
word_lem=WordNetLemmatizer()

word_lem.lemmatize('corpora')

for words in words_to_stem:
  print(words+ ":" +word_lem.lemmatize(words))

from nltk.corpus import stopwords

stopwords.words('english')

len(stopwords.words('english'))

fdist_top10

import re
punctuation=re.compile(r'[-.?!,:;()|0-9]')

post_punctuation=[]
for words in AI_tokens:
  word=punctuation.sub("",words)
  if len(word)>0:
    post_punctuation.append(word)

post_punctuation

sent = "Lauren is a natural when it comes to drawing"
sent_tokens = word_tokenize(sent)

for token in sent_tokens:
  print(nltk.pos_tag([token]))

sent2 = "Clara is eating a delicious cake"
sent2_tokens = word_tokenize(sent2)
for token in sent2_tokens:
  print(nltk.pos_tag([token]))

from nltk import ne_chunk

NE_sent = "The Ministry of Health in Indonesia announced a new collaboration with the World Health Organization on Monday morning."

NE_tokens = word_tokenize(NE_sent)
NE_tags = nltk.pos_tag(NE_tokens)

NE_NER = ne_chunk(NE_tags)
print(NE_NER)

new = "The big cat ate the little mouse who was after fresh cheese"
new_tokens = nltk.pos_tag(word_tokenize(new))
new_tokens

grammar_np = r"NP: {<DT>?<JJ>*<NN>}"

chunk_parser = nltk.RegexpParser(grammar_np)

chunk_result = chunk_parser.parse(new_tokens)
print(chunk_result)

from nltk import Tree
import matplotlib.pyplot as plt

def draw_tree(tree):
    fig = plt.figure(figsize=(12,8))
    _ = tree.pretty_print()

draw_tree(chunk_result)